{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We will be using the BERT model and tokenizer from Hugging Face's transformers library. Additionally, the regular expressions module is used to preprocess our protein sequence to make it compatible with the model's expected input format.\n",
    "\n",
    "We then load a tokenizer for protein sequences from the model hub, and then load the pre-trained protein sequence BERT model which acts as our encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "import re\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(\"Rostlab/prot_bert\")\n",
    "config.max_position_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We'll define a sample protein sequence and preprocess it. Specifically, the U, Z, O, and B amino acids are much less common. For the purposes of standardizing input for the model, they are replaced by \"X\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_Example = \"A E T C Z A O\"\n",
    "sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "Now, we tokenize the sequence to convert it into a format that the BERT model understands. We use PyTorch tensors (`pt`) as that's the format the model expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:748\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tensor(value):\n\u001b[1;32m--> 748\u001b[0m     tensor \u001b[39m=\u001b[39m as_tensor(value)\n\u001b[0;32m    750\u001b[0m     \u001b[39m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[0;32m    751\u001b[0m     \u001b[39m# # at-least2d\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     \u001b[39m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[0;32m    753\u001b[0m     \u001b[39m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[0;32m    754\u001b[0m     \u001b[39m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[0;32m    755\u001b[0m     \u001b[39m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:720\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[1;34m(value, dtype)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mtensor(np\u001b[39m.\u001b[39marray(value))\n\u001b[1;32m--> 720\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mtensor(value)\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 9 at dim 1 (got 15)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tatwo\\Desktop\\Programs\\Wolfram\\WELP-PLAPT\\protein_encoder.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tatwo/Desktop/Programs/Wolfram/WELP-PLAPT/protein_encoder.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokens \u001b[39m=\u001b[39m tokenizer([sequence_Example,\u001b[39m\"\u001b[39;49m\u001b[39mA E T C Z A X\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mA E T C Z A X X X X X X X\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mA E T C Z A X X X X X\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mA E T C Z A X X X X X X X\u001b[39;49m\u001b[39m\"\u001b[39;49m],truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:2790\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2788\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2789\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2790\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[0;32m   2791\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2792\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:2876\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2871\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2872\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2873\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2874\u001b[0m         )\n\u001b[0;32m   2875\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[1;32m-> 2876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[0;32m   2877\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[0;32m   2878\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   2879\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   2880\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[0;32m   2881\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   2882\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   2883\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   2884\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   2885\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   2886\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   2887\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   2888\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   2889\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   2890\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   2891\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   2892\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   2893\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2894\u001b[0m     )\n\u001b[0;32m   2895\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2896\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[0;32m   2897\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[0;32m   2898\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2914\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2915\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:3067\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3058\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3059\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[0;32m   3060\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3064\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3065\u001b[0m )\n\u001b[1;32m-> 3067\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[0;32m   3068\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[0;32m   3069\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m   3070\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m   3071\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m   3072\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m   3073\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m   3074\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[0;32m   3075\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m   3076\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m   3077\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m   3078\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m   3079\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m   3080\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m   3081\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[0;32m   3082\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m   3083\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   3084\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   3085\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils.py:807\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    804\u001b[0m     second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n\u001b[1;32m--> 807\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_prepare_for_model(\n\u001b[0;32m    808\u001b[0m     input_ids,\n\u001b[0;32m    809\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[0;32m    810\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[0;32m    811\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[0;32m    812\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[0;32m    813\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[0;32m    814\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[0;32m    815\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[0;32m    816\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[0;32m    817\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[0;32m    818\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[0;32m    819\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[0;32m    820\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[0;32m    821\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    822\u001b[0m )\n\u001b[0;32m    824\u001b[0m \u001b[39mreturn\u001b[39;00m BatchEncoding(batch_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils.py:887\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_prepare_for_model\u001b[1;34m(self, batch_ids_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_length, verbose)\u001b[0m\n\u001b[0;32m    877\u001b[0m         batch_outputs[key]\u001b[39m.\u001b[39mappend(value)\n\u001b[0;32m    879\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad(\n\u001b[0;32m    880\u001b[0m     batch_outputs,\n\u001b[0;32m    881\u001b[0m     padding\u001b[39m=\u001b[39mpadding_strategy\u001b[39m.\u001b[39mvalue,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    884\u001b[0m     return_attention_mask\u001b[39m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m    885\u001b[0m )\n\u001b[1;32m--> 887\u001b[0m batch_outputs \u001b[39m=\u001b[39m BatchEncoding(batch_outputs, tensor_type\u001b[39m=\u001b[39;49mreturn_tensors)\n\u001b[0;32m    889\u001b[0m \u001b[39mreturn\u001b[39;00m batch_outputs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:223\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[1;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[0;32m    219\u001b[0m     n_sequences \u001b[39m=\u001b[39m encoding[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn_sequences\n\u001b[0;32m    221\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_sequences \u001b[39m=\u001b[39m n_sequences\n\u001b[1;32m--> 223\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_to_tensors(tensor_type\u001b[39m=\u001b[39;49mtensor_type, prepend_batch_axis\u001b[39m=\u001b[39;49mprepend_batch_axis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:764\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[1;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39moverflowing_tokens\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    760\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    761\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    762\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    763\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    765\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to create tensor, you should probably activate truncation and/or padding with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    766\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpadding=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtruncation=True\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to have batched tensors with the same length. Perhaps your\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    767\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m features (`\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m` in this case) have excessive nesting (inputs type `list` where type `int` is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    768\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m expected).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    769\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected)."
     ]
    }
   ],
   "source": [
    "tokens = tokenizer([sequence_Example,\"A E T C Z A X\",\"A E T C Z A X X X X X X X\",\"A E T C Z A X X X X X\",\"A E T C Z A X X X X X X X\"],truncation=True, max_length=512,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2,  6,  9, 15, 23, 25,  6, 25,  3],\n",
       "        [ 2,  6,  9, 15, 23, 28,  6, 25,  3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching Embeddings from BERT\n",
    "\n",
    "With the processed sequence, fetch the embeddings or representations from the BERT model. These embeddings can be utilized for further analysis, such as classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encodings=model(**tokens).last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(encodings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0639,  0.0582, -0.0569,  ..., -0.0532, -0.0593,  0.0873],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
