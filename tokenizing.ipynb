{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Manim\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries, load model and tokenizer\n",
    "from transformers import RobertaTokenizer, RobertaModel, BertModel, BertTokenizer, BertConfig\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "\n",
    "mole_tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "mole_model = RobertaModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "\n",
    "pro_tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False)\n",
    "pro_model = BertModel.from_pretrained(\"Rostlab/prot_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function that tokenize the molecules\n",
    "def mole_tokenize_and_encode(molecules):\n",
    "    tokens = mole_tokenizer(molecules, padding=True, return_tensors='pt')\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = mole_model(**tokens)\n",
    "    # embeddings = outputs.last_hidden_state\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to tokenize the proteins\n",
    "def pro_tokenize_and_encode(proteins):\n",
    "    tokens = pro_tokenizer(proteins, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = pro_model(**tokens)\n",
    "    # embeddings = outputs.last_hidden_state\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "dataset = load_dataset(\"jglaser/binding_affinity\")[\"train\"]\n",
    "\n",
    "proteins = dataset['seq'][:10]\n",
    "molecules = dataset['smiles'][:10]\n",
    "\n",
    "# Preprocess Protein\n",
    "proteins = [re.sub(r\"[UZOB]\", \"X\", protein) for protein in proteins]\n",
    "proteins = [\" \".join(protein) for protein in proteins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M T V P D R S E I A G K W Y V V A L A S']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 2, 21, 15,  8, 16, 14, 13, 10,  9, 11,  6,  7, 12, 24, 20,  8,  8,  6,\n",
       "          5,  6, 10,  3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_Example = [\"MTVPDRSEIAGKWYVVALAS\"]\n",
    "s = [\" \".join(protein) for protein in sequence_Example]\n",
    "print(s)\n",
    "tokens = pro_tokenizer(s,padding=True,truncation=True, max_length=512,return_tensors='pt')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Data through tokenizer:\n",
    "pro_tokenized = pro_tokenize_and_encode(proteins)\n",
    "pro_list = pd.DataFrame(pro_tokenized['input_ids'].numpy())\n",
    "\n",
    "mole_tokenized = mole_tokenize_and_encode(molecules)\n",
    "mole_list = pd.DataFrame(mole_tokenized['input_ids'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving To csv\n",
    "pro_list.to_csv(r'Data\\protein\\protein.csv', index=False, header=False)\n",
    "mole_list.to_csv(r'Data\\molecule\\molecule.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
